# Intro_DeepLearning

## üìå Introduction
This repository contains five laboratory exercises on **Convolutional Neural Networks (CNNs)**, covering fundamental concepts, model training, optimization techniques, and performance evaluation. The labs explore different architectures, including ResNet and VGG, and experiment with various training strategies.

## üìÇ Lab Summaries

### **1Ô∏è‚É£ Week_01 - Introduction to CNNs**
- Overview of Convolutional Neural Networks (CNNs).
- Key components: Convolutional Layers, Pooling Layers, Fully Connected Layers.
- Explanation of Depthwise Separable Convolution and MixConv.

### **2Ô∏è‚É£ Lab 02 - Implementing a Basic CNN Model**
- Introduction to CNN model implementation.
- Building and training a simple CNN architecture (content not detailed in markdown).

### **3Ô∏è‚É£ Lab 03 - Training CNN on a Large Dataset**
- Training a CNN model on the full dataset for 5 epochs.
- Experimenting with **VGG-C** and **VGG-E** models.
- Evaluating and comparing model performance on the test set.

### **4Ô∏è‚É£ Lab 04 - Implementing ResNet-101**
- Implementing the ResNet-101 architecture from scratch.
- Training the model with different batch sizes (`batch_size = 32` and `batch_size = 64`).
- Analyzing the impact of batch size on model convergence and performance.

### **5Ô∏è‚É£ Lab 05 - Model Fine-Tuning and Optimization**
- Optimization techniques to improve CNN training (content not detailed in markdown).
